# Matrix-Multiplication-Fox-Algorithm

This project implements the FOX Parallel Matrix Multiplication Algorithm using Python for high-performance, distributed, and GPU-accelerated computation. It demonstrates parallel algorithm design using NumPy, Numba CUDA, and MPI4Py, along with performance benchmarking on multi-core and multi-node systems.

## overview
The FOX algorithm is an efficient method for performing matrix multiplication on a 2D process grid. This implementation supports:
- Multi-core CPU parallelism
- CUDA GPU acceleration (Numba CUDA)
- Distributed execution using MPI (MPI4Py)
- Scalable performance across q √ó q process grids
- Benchmarking for runtime, speedup, and memory usage

## Key Features

‚úîÔ∏è Fully implemented FOX algorithm with block matrix decomposition

‚úîÔ∏è Supports q √ó q distributed process grid

‚úîÔ∏è Optimized GPU kernel using Numba CUDA

‚úîÔ∏è MPI-based broadcasting and data shifting logic

‚úîÔ∏è Benchmarks for N = 256‚Äì2048 with speedup up to 12√ó

‚úîÔ∏è Handles race conditions, synchronization issues, and CUDA memory errors

‚úîÔ∏è Produces validated results compared to serial baseline multiplication

‚öôÔ∏è Technologies Used
- Python 3.10+
- NumPy
- Numba (CUDA kernels)
- MPI4Py
- CUDA Toolkit (11 or higher)
- Matplotlib (for plotting benchmark results)

üìò Algorithm Summary
- The FOX algorithm divides matrices into q √ó q sub-blocks, then:
- Broadcasts appropriate sub-blocks across each row
- Each process performs local matrix multiplication
- Cyclically shifts sub-blocks of matrix B upward
- Repeats for q iterations to compute local sub-results
- Collects and assembles the final output matrix
- This minimizes communication overhead and ensures balanced workload distribution.
